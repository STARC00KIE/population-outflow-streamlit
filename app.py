# app.py â€” Streamlit ê°œìš” íƒ­ ë¼ˆëŒ€ (ì²­ë…„ ìœ ì¶œ í”„ë¡œì íŠ¸)
# -----------------------------------------------------
# ì´ íŒŒì¼ì€ 'ê°œìš”' íƒ­ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œ í¬íŠ¸í´ë¦¬ì˜¤í˜• ëŒ€ì‹œë³´ë“œ ì…ë‹ˆë‹¤.
# - ì‚¬ì´ë“œë°”: ë°ì´í„° ì—…ë¡œë“œ(ì„ íƒ), ì—°ë„/ì§€ì—­ í•„í„°(ìƒ˜í”Œ)
# - íƒ­: [ê°œìš”] [ë°ì´í„°/EDA] [ëª¨ë¸/ì¤‘ìš”ë„] [ì§€ì—­ë³„ ë¦¬í¬íŠ¸] [ì •ì±… ì‹œë‚˜ë¦¬ì˜¤] [ë¬¸ì„œ/ë§í¬]
# ì‹¤ì œ ë°ì´í„° ì»¬ëŸ¼ëª…ì— ë§ì¶° TODO ë¶€ë¶„ë§Œ ì±„ìš°ë©´ ë°”ë¡œ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.

import io
import textwrap
from typing import Dict, List, Optional

import numpy as np
import pandas as pd
import seaborn as sns
import json
import joblib

from matplotlib import rcParams
import matplotlib.pyplot as plt

import streamlit as st
from streamlit_folium import st_folium

import folium
from folium.plugins import TimeSliderChoropleth

from typing import List, Tuple, Optional, Dict, Any
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import shap

# í•œê¸€ í°íŠ¸ ì§€ì • (Windows: ë§‘ì€ ê³ ë”•)
rcParams['font.family'] = 'Malgun Gothic'
# ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
rcParams['axes.unicode_minus'] = False

# ---------------------------------
# 0) í˜ì´ì§€ ì„¤ì •
# ---------------------------------
st.set_page_config(
    page_title="ì²­ë…„ ìœ ì¶œ í¬íŠ¸í´ë¦¬ì˜¤ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide",
)

# ---------------------------------
# 1) ì „ì—­ ë©”íƒ€/ì„¤ì • (í”„ë¡œì íŠ¸ ê³ ì •ê°’)
# ---------------------------------
PROJECT_META = {
    "title": "ì§€ì—­ì‚¬íšŒ í™œë ¥ íšŒë³µì„ ìœ„í•œ ì²­ë…„ ì¸êµ¬ ìœ ì¶œ ìš”ì¸ ë¶„ì„",
    "subtitle": "2020â€“2023ë…„ ì‹œêµ°êµ¬ ë‹¨ìœ„ ë¶„ì„ê³¼ ì •ì±… ì‹œë‚˜ë¦¬ì˜¤",
    "period": "2025.07â€“2025.09",
    "unit": "ì‹œêµ°êµ¬ 229ê°œ",
    "target": "ì²­ë…„ ìˆœì´ë™ë¥ (ìˆœìœ ì¶œ/ìˆœìœ ì…)",
    "models": ["ElasticNet", "XGBoost"],
    "core_vars": ["CMR(ì¡°í˜¼ì¸ìœ¨)", "INDUSTRIAL_AREA(ê³µì—…ì§€ì—­ ë¹„ì¤‘)", "SELF_FINANCE(ì¬ì •ìë¦½ë„)"],
    "team": [
        {"name": "ê¹€ì¢…í˜„", "role": "ì´ê´„/ì¼ì • ê³„íš ê´€ë¦¬"},
        {"name": "ì¡°ì¬í™", "role": "ìë£Œ ë¦¬ì„œì¹˜, ì‹œê°í™”"},
        {"name": "ê°•í˜¸í˜„", "role": "QGIS/Tableau ì‹œê°í™”, íšŒê·€ì‹ ì„¤ê³„"},
        {"name": "ì˜¤ìˆ˜ì„±", "role": "ë°ì´í„° ëª¨ë¸ë§, Streamlit ëŒ€ì‹œë³´ë“œ êµ¬ì¶•"},
    ],
    "duration": "2025-07 ~ 2025-09",
}

# ---------------------------------
# 2) ìœ í‹¸
# ---------------------------------

### ìƒ˜í”Œ ë°ì´í„° & ë¡œë”
@st.cache_data
def make_demo(n_regions: int = 40, years: List[int] = [2020, 2021, 2022, 2023]) -> pd.DataFrame:
    rng = np.random.default_rng(42)
    rows = []
    for y in years:
        for i in range(n_regions):
            sgg = f"ê°€ìƒì‹œêµ°êµ¬{i+1:03d}"
            cmr = rng.normal(5.0, 1.2)
            ind = abs(rng.normal(20, 6))  # ì‚°ì—…ì§€ì—­ ë¹„ì¤‘ ê°€ìƒê°’
            sf = rng.uniform(20, 80)      # ì¬ì •ìë¦½ë„ ê°€ìƒê°’
            youth_net = rng.normal(0.0, 3.5) - 0.12 * (ind/10) + 0.25 * (cmr-5) + 0.05 * (sf-50)
            rows.append({
                "YEAR": y,
                "SGG_NAME": sgg,
                "CMR": cmr,
                "INDUSTRIAL_AREA": ind,
                "SELF_FINANCE": sf,
                "YOUTH_NET_RATE": youth_net,
            })
    return pd.DataFrame(rows)

@st.cache_data
def load_data(file: io.BytesIO | None) -> pd.DataFrame:
    if file is None:
        try:
            # streamlit/data/streamlit_data.csv ì‚¬ìš©
            df = pd.read_csv("./streamlit/data/streamlit_data.csv")
        except FileNotFoundError:
            df = make_demo()
            st.caption("ë°ëª¨ ë°ì´í„°ë¥¼ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. (streamlit_data.csv ì—†ìŒ)")
    else:
        try:    
            df = pd.read_csv(file)
        except UnicodeDecodeError:
            df = pd.read_csv(file, encoding="cp949")
    return df


### geojson ìœ í‹¸
@st.cache_data
def load_geojson(path: str) -> dict:
    """GeoJSON íŒŒì¼ì„ dict í˜•íƒœë¡œ ë¡œë“œ"""
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def draw_choropleth(df, geojson_obj, year: int, value_col: str,
                    key_col: str = "BJCD", center=[36.5, 127.8], zoom=7):
    """
    ë‹¨ì¼ ì—°ë„ë³„ Choropleth ì§€ë„ ìƒì„± í›„ Streamlitì— í‘œì‹œ

    Parameters:
        df (pd.DataFrame): ì—°ë„ë³„ ë°ì´í„° (SGG_CODE, YEAR, ê°’ í¬í•¨)
        geojson_obj (dict): ë¡œë“œëœ GeoJSON ê°ì²´
        year (int): ì„ íƒëœ ì—°ë„
        value_col (str): ì§€ë„ì— í‘œì‹œí•  ë³€ìˆ˜ëª…
        key_col (str): GeoJSONê³¼ ë§¤í•‘í•  í‚¤
    """
    df_year = df[df["YEAR"] == year]

    m = folium.Map(location=center, zoom_start=zoom, tiles="cartodbpositron")

    folium.Choropleth(
        geo_data=geojson_obj,
        data=df_year,
        columns=[key_col, value_col],
        key_on=f"feature.properties.{key_col}",
        fill_color="YlOrRd",
        fill_opacity=0.8,
        line_opacity=0.2,
        nan_fill_color="white",
        legend_name=value_col,
    ).add_to(m)

    st_folium(m, width=900, height=650)


### modeling ìœ í‹¸
def extract_final_model(obj):
    """GridSearchCVë©´ best_estimator_ ì¶”ì¶œ, ì•„ë‹ˆë©´ ì›ë³¸ ë°˜í™˜."""
    if hasattr(obj, "best_estimator_") and obj.best_estimator_ is not None:
        return obj.best_estimator_
    return obj

def load_models_from_paths(paths):
    """ë¡œì»¬ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ëª¨ë¸ ì½ê¸°."""
    loaded, errors = [], []
    for p in paths:
        try:
            obj = joblib.load(p)
            model = extract_final_model(obj)
            display_name = p.split("/")[-1]
            feat_from_model = getattr(model, "feature_names_", None)
            loaded.append((display_name, model, feat_from_model))
        except Exception as e:
            errors.append(f"{p}: {e}")
    return loaded, errors

def align_features(X_all: pd.DataFrame, feat_from_model):
    """
    ëª¨ë¸ì— feature_names_ê°€ ìˆìœ¼ë©´ êµì§‘í•© ì •ë ¬.
    return: (X_use, feat_names, missing)
    """
    if feat_from_model:
        missing = [c for c in feat_from_model if c not in X_all.columns]
        used_cols = [c for c in feat_from_model if c in X_all.columns]
        if not used_cols:
            return pd.DataFrame(index=X_all.index), [], missing
        return X_all[used_cols], used_cols, missing
    return X_all, list(X_all.columns), []

def evaluate_model(model, X: pd.DataFrame, y: pd.Series):
    """RMSE/MAE/RÂ² ê³„ì‚°."""
    y_pred = model.predict(X)
    return {
        "rmse": float(np.sqrt(mean_squared_error(y, y_pred))),
        "mae": float(mean_absolute_error(y, y_pred)),
        "r2": float(r2_score(y, y_pred)),
    }

def get_importance_series(model, feat_names):
    """íŠ¸ë¦¬/ì„ í˜•/íŒŒì´í”„ë¼ì¸ì—ì„œ ë³€ìˆ˜ì¤‘ìš”ë„ ì¶”ì¶œ."""
    try:
        if hasattr(model, "feature_importances_"):
            return pd.Series(model.feature_importances_, index=feat_names).sort_values(ascending=False)
        if hasattr(model, "coef_"):
            coef = np.ravel(model.coef_)
            return pd.Series(np.abs(coef), index=feat_names).sort_values(ascending=False)
        if hasattr(model, "steps"):
            last_est = model.steps[-1][1]
            if hasattr(last_est, "feature_importances_"):
                return pd.Series(last_est.feature_importances_, index=feat_names).sort_values(ascending=False)
            if hasattr(last_est, "coef_"):
                coef = np.ravel(last_est.coef_)
                return pd.Series(np.abs(coef), index=feat_names).sort_values(ascending=False)
    except Exception:
        return None
    return None

def choose_shap_explainer(model, X_use: pd.DataFrame):
    """
    ëª¨ë¸ ìœ í˜•ì— ë§ì¶° ì ì ˆí•œ SHAP Explainerë¥¼ ìƒì„±í•´ ë°˜í™˜.
    return: (explainer, method_str, base_model_for_pred)
    """

    m = model
    m_str = str(type(m)).lower()

    # íŒŒì´í”„ë¼ì¸ì´ë©´ ë§ˆì§€ë§‰ ì¶”ì •ê¸°
    if hasattr(model, "steps"):
        m = model.steps[-1][1]
        m_str = str(type(m)).lower()

    if any(k in m_str for k in ["xgboost", "lightgbm", "randomforest", "gradientboosting"]):
        explainer = shap.TreeExplainer(m)
        return explainer, "tree", m
    elif any(k in m_str for k in ["linear", "elasticnet", "lasso", "ridge", "sgdregressor"]):
        explainer = shap.LinearExplainer(m, X_use, feature_perturbation="interventional")
        return explainer, "linear", m
    else:
        background = shap.sample(X_use, min(200, len(X_use)), random_state=42)
        explainer = shap.KernelExplainer(m.predict, background)
        return explainer, "kernel", m

def mean_abs_shap_top(sv: np.ndarray, X_sample: pd.DataFrame, top_k: int = 15):
    """í‰ê·  |SHAP| ìƒìœ„í‘œ."""
    mean_abs = np.abs(sv).mean(axis=0)
    return pd.Series(mean_abs, index=X_sample.columns).sort_values(ascending=False).head(top_k).rename("mean|SHAP|").to_frame()

### ì§€ì—­ë³„ ë¦¬í¬íŠ¸ ìœ í‹¸
def find_col_ci(df: pd.DataFrame, *candidates: str) -> str | None:
    """ëŒ€ì†Œë¬¸ì ë¬´ì‹œë¡œ df ì»¬ëŸ¼ëª… ë§¤ì¹­í•˜ì—¬ ì²« ì¼ì¹˜ ì»¬ëŸ¼ ë°˜í™˜."""
    lc = {c.lower(): c for c in df.columns}
    for cand in candidates:
        if cand is None:
            continue
        if cand.lower() in lc:
            return lc[cand.lower()]
    return None

def pct_rank(series: pd.Series, value: float) -> float:
    """ë¶„ìœ„(%): seriesì—ì„œ valueê°€ ì•„ë˜ì— ìˆëŠ” ë¹„ìœ¨(0~100)."""
    s = series.dropna()
    if pd.notnull(value) and len(s):
        return float((s < value).mean() * 100.0)
    return np.nan

def ensure_bjcd_string(df: pd.DataFrame, col: str = "BJCD") -> pd.DataFrame:
    """BJCD â†’ ë¬¸ìì—´ ë³´ì¥."""
    df = df.copy()
    df[col] = df[col].astype(str)
    return df

def make_val_map(df: pd.DataFrame, code_col: str, value_cols, name_col: str):
    """
    BJCD -> {ì—¬ëŸ¬ ê°’ë“¤..., name} ë”•ì…”ë„ˆë¦¬ ìƒì„±.
    value_cols: str ë˜ëŠ” [str, ...]
    """
    if isinstance(value_cols, str):
        cols = [value_cols]
    else:
        cols = list(value_cols)

    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    cols = [c for c in cols if c in df.columns]
    use_cols = [code_col, name_col] + cols
    if not cols:
        # ê°’ ì»¬ëŸ¼ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì´ë¦„ë§Œ ë‹´ì•„ë‘”ë‹¤
        use_cols = [code_col, name_col]

    return (
        df[use_cols]
        .dropna(subset=[code_col])
        .set_index(code_col)[[c for c in use_cols if c != code_col]]
        .to_dict(orient="index")
    )

def extract_bjcd_from_popup(popup_text: str) -> str | None:
    """folium popup í…ìŠ¤íŠ¸ì—ì„œ 'CODE: 12345' íŒ¨í„´ìœ¼ë¡œ BJCD ì¶”ì¶œ."""
    import re
    if not popup_text:
        return None
    m = re.search(r"(?:ì½”ë“œ|CODE)\s*[:ï¼š]\s*(\d+)", str(popup_text))
    return m.group(1) if m else None

def feature_bounds(feat):
    """GeoJSON featureì˜ ê²½ê³„ [[south, west], [north, east]] ë°˜í™˜."""
    try:
        coords = []
        geom = feat.get("geometry", {})
        t = geom.get("type", "")
        if t == "Polygon":
            for ring in geom["coordinates"]:
                coords.extend(ring)   # [lon, lat]
        elif t == "MultiPolygon":
            for poly in geom["coordinates"]:
                for ring in poly:
                    coords.extend(ring)
        if not coords:
            return None
        lons = [c[0] for c in coords]
        lats = [c[1] for c in coords]
        return [[min(lats), min(lons)], [max(lats), max(lons)]]
    except Exception:
        return None

def popup_html_for_code(code_, val_map: dict, popup_cols: list, label_map: dict, name_key: str):
    """
    ì„ íƒ ì½”ë“œì˜ íŒì—… HTML ìƒì„±.
    - code_: BJCD ë¬¸ìì—´
    - val_map: {BJCD: {<col>: value, name_key: ì§€ì—­ëª…, ...}}
    - popup_cols: íŒì—…ì— ë³´ì—¬ì¤„ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    - label_map: í™”ë©´ì— ë³´ì—¬ì¤„ ë¼ë²¨ ë§¤í•‘ {col_name: "ë¼ë²¨"}
    - name_key: ì§€ì—­ëª… í‚¤(ì˜ˆ: 'SGG_NAME')
    """
    rec = val_map.get(str(code_))
    if not rec:
        return f"CODE: {code_}<br>(ë°ì´í„° ì—†ìŒ)"

    lines = [f"<b>{rec.get(name_key, '')}</b>", f"CODE: {code_}"]
    for col in popup_cols:
        v = rec.get(col)
        label = label_map.get(col, col)
        if isinstance(v, (int, float, np.number)) and pd.notnull(v):
            lines.append(f"{label}: {v:,.3f}")
        elif v is not None and str(v) != "nan":
            lines.append(f"{label}: {v}")
    return "<br>".join(lines)

# ---------------------------------
# 3-1) ê°œìš” íƒ­ ë Œë”ëŸ¬
# ---------------------------------
def render_overview_tab(df: pd.DataFrame, meta: Dict):
    # í—¤ë” ì˜ì—­
    c1, c2 = st.columns([0.75, 0.25])
    with c1:
        st.markdown(f"# {meta['title']}")
        st.markdown(f"**{meta['subtitle']}**")
        st.markdown("""
            **ëª©í‘œ**  
            - ì§€ì—­ë³„ ì²­ë…„ ìˆœì´ë™ë¥ (YOUTH_NET_MOVE_RATE)ì„ ë°ì´í„°ë¡œ ì„¤ëª…í•˜ê³ , ì •ì±… ë ˆë²„(CMRÂ·SELF_FINANCEÂ·INDUSTRIAL_AREA ë“±)ë¥¼ ì¡°ì •í–ˆì„ ë•Œ
            ì˜ˆì¸¡ì´ ì–´ë–»ê²Œ ë°”ë€ŒëŠ”ì§€ **What-if ì‹œë‚˜ë¦¬ì˜¤**ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.

            **ì™œ í•„ìš”í•œê°€?**  
            - ì²­ë…„ ìœ ì¶œ/ìœ ì…ì˜ **í•µì‹¬ ìš”ì¸**ì„ íŒŒì•…í•´ ê·¼ê±° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ ë•ìŠµë‹ˆë‹¤.  
            - **ì–´ëŠ ì§€ì—­**ì´ ê¸°íšŒ/ìœ„í—˜ êµ¬ê°„ì¸ì§€, **ì–´ë–¤ ì •ì±… ë ˆë²„**ê°€ íš¨ê³¼ì ì¸ì§€ ë¹„êµí•©ë‹ˆë‹¤.  
            - ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í†µí•´ **ì •ì±… ìš°ì„ ìˆœìœ„**ì™€ **ì˜ˆìƒ íš¨ê³¼ ê·œëª¨**ë¥¼ ê°€ëŠ í•©ë‹ˆë‹¤.
            """)
    with c2:
        st.markdown("### í”„ë¡œì íŠ¸ ì •ë³´")
        st.markdown(f"- ê¸°ê°„: **{meta['period']}**")
        st.markdown(f"- ë‹¨ìœ„: **{meta['unit']}**")
        st.markdown(f"- ë…ë¦½ë³€ìˆ˜: **{meta['target']}**")

    st.divider()

    # í•µì‹¬ ì§ˆë¬¸
    with st.container():
        st.subheader("í•µì‹¬ ì§ˆë¬¸ (Research Questions)")
        st.markdown("- ì–´ë–¤ ìš”ì¸ë“¤ì´ ì²­ë…„ ìœ ì¶œ/ìœ ì…ì„ ì„¤ëª…í•˜ëŠ”ê°€?")
        st.markdown("- ìš”ì¸ë“¤ì˜ ì§€ì—­, ìœ í˜•ë³„ ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€?")
        st.markdown("- ì •ì±…ì  ê°œì„  ë°©ì•ˆì€ ë¬´ì—‡ì¸ê°€?")

    st.divider()

    # ë°ì´í„° ìŠ¤ëƒ…ìƒ· & ìš”ì•½ ë©”íŠ¸ë¦­
    with st.container():
        st.subheader("ë°ì´í„° ê°œìš”")
        total_rows = len(df)
        n_years = df["YEAR"].nunique() if "YEAR" in df.columns else None
        n_regions = df["SGG_NAME"].nunique() if "SGG_NAME" in df.columns else None

        m1, m2, m3 = st.columns(3)
        m1.metric("ì´ í–‰ ìˆ˜", f"{total_rows:,}")
        m2.metric("ì—°ë„ ìˆ˜", n_years if n_years is not None else "â€”")
        m3.metric("ì§€ì—­ ìˆ˜", n_regions if n_regions is not None else "â€”")

        st.dataframe(df.head(10), use_container_width=True)

    st.divider()

    # ë°©ë²•ë¡  ìš”ì•½ (íŒŒì´í”„ë¼ì¸)
    with st.container():
        st.subheader("ë°©ë²•ë¡  ìš”ì•½")
        st.markdown(
            "â¡ï¸ **ì •ì œ â†’ ì „ì²˜ë¦¬ â†’ EDA â†’ ë³€ìˆ˜ì„ íƒ â†’ ëª¨ë¸ë§ â†’ ì •ì±… ì‹œë‚˜ë¦¬ì˜¤**"
        )
        # ê°„ë‹¨í•œ Graphviz ë‹¤ì´ì–´ê·¸ë¨ (ì„ íƒ)
        try:
            st.graphviz_chart(
                """
                digraph G {
                  rankdir=LR;
                  A[label="ì •ì œ"]; B[label="ì „ì²˜ë¦¬"]; C[label="EDA"]; D[label="ë³€ìˆ˜ì„ íƒ"]; E[label="ëª¨ë¸ë§"]; F[label="ì •ì±… ì‹œë‚˜ë¦¬ì˜¤"];
                  A -> B -> C -> D -> E -> F;
                }
                """
            )
        except Exception:
            st.info("Graphviz ë Œë”ê°€ ë¶ˆê°€í•œ í™˜ê²½ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ì„ í™•ì¸í•˜ì„¸ìš”.")

        st.markdown("**ì‚¬ìš© ëª¨ë¸**: " + ", ".join(meta["models"]))
        st.caption("ElasticNet(í•´ì„ë ¥), XGBoost(ë¹„ì„ í˜•Â·ìƒí˜¸ì‘ìš©Â·ì˜ˆì¸¡ë ¥)")

    st.divider()

    # í•µì‹¬ ê²°ê³¼ ìš”ì•½ (í•˜ì´ë¼ì´íŠ¸ ì¹´ë“œ)
    with st.container():
        st.subheader("í•µì‹¬ ê²°ê³¼ ìš”ì•½")
        st.markdown("- ìƒìœ„ í•µì‹¬ ë³€ìˆ˜: **" + ", ".join(meta["core_vars"]) + "**")
        c1, c2, c3 = st.columns(3)
        c1.info("ì¡°í˜¼ì¸ìœ¨ ì¦ê°€ â†—ï¸ â†’ ìˆœì´ë™ë¥  ê°œì„  ê²½í–¥")
        c2.info("ê³µì—…ì§€ì—­ ë©´ì  ì¦ëŒ€ â†—ï¸ â†’ ìˆœì´ë™ë¥ ì— ë³µí•©ì  ì˜í–¥")
        c3.info("ì¬ì •ìë¦½ë„ í–¥ìƒ â†—ï¸ â†’ ì •ì±… ì¶”ì§„ ê¸°ë°˜ ê°•í™”")

    st.divider()

    # íŒ€/ê¸°ê°„
    with st.container():
        st.subheader("íŒ€ ì—­í•  & ê¸°ê°„")
        t1, t2 = st.columns([0.6, 0.4])
        with t1:
            for m in meta["team"]:
                st.markdown(f"- **{m['name']}** â€” {m['role']}")
        with t2:
            st.markdown(f"**ì§„í–‰ ê¸°ê°„**: {meta['duration']}")

    st.divider()


# ---------------------------------
# 3-2)EDA íƒ­ ë Œë”ëŸ¬
# ---------------------------------
def render_eda_tab(df: pd.DataFrame):
    st.header("íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)")

    # 0) ì„ íƒ í•„í„° (ì—°ë„)
    filtered = df.copy()

    # 1) ë°ì´í„° êµ¬ì¡°
    st.subheader("ë°ì´í„° êµ¬ì¡° ìš”ì•½")
    n_rows, n_cols = filtered.shape
    m1, m2 = st.columns(2)
    m1.metric("í–‰(Row)", f"{n_rows:,}")
    m2.metric("ì—´(Col)", f"{n_cols:,}")

    st.divider()
    
    # 2) ê¸°ìˆ í†µê³„
    st.subheader("ê¸°ìˆ í†µê³„")
    num_cols = filtered.select_dtypes(include=["number"]).columns.tolist()
    if num_cols:
        st.dataframe(filtered[num_cols].describe().T)
    else:
        st.info("ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()

    # 3) íƒ€ê¹ƒ ë° ì£¼ìš” ë³€ìˆ˜ ë¶„í¬
    st.subheader("ë¶„í¬ íƒìƒ‰")
    target_col = "YOUTH_NET_RATE" if "YOUTH_NET_RATE" in filtered.columns else None
    default_feats = [c for c in ["CMR", "INDUSTRIAL_AREA", "SELF_FINANCE"] if c in filtered.columns]
    pick_cols = st.multiselect(
        "ë¶„í¬ í™•ì¸í•  ì»¬ëŸ¼ ì„ íƒ", 
        options=[c for c in num_cols if c != target_col],
        default=default_feats
    )

    # íƒ€ê¹ƒ ë¶„í¬
    if target_col:
        st.markdown(f"**íƒ€ê¹ƒ ë¶„í¬: {target_col}**")
        fig, ax = plt.subplots()
        ax.hist(filtered[target_col].dropna(), bins=30)
        ax.set_xlabel(target_col)
        ax.set_ylabel("count")
        st.pyplot(fig)

    # ì„ íƒ ì»¬ëŸ¼ ë¶„í¬ ê·¸ë¦¬ë“œ(2ì—´)
    if pick_cols:
        cols = st.columns(2)
        for i, col in enumerate(pick_cols):
            fig, ax = plt.subplots()
            ax.hist(filtered[col].dropna(), bins=30)
            ax.set_xlabel(col)
            ax.set_ylabel("count")
            cols[i % 2].pyplot(fig)

    st.divider()

    # 4) ìƒê´€ë¶„ì„
    num_cols_all = [c for c in filtered.columns 
                    if pd.api.types.is_numeric_dtype(filtered[c])]
    candidates = [c for c in num_cols_all if c != target_col]

    st.subheader("ìƒê´€ê´€ê³„ ë¶„ì„")

    # 4-1) ë¶„ì„ ëŒ€ìƒ ë³€ìˆ˜ ì„ íƒ (ì—†ìœ¼ë©´ ì „ì²´ ìˆ«ìí˜•)
    sel_vars = st.multiselect(
        "ìƒê´€ë¶„ì„ì— í¬í•¨í•  ë³€ìˆ˜ ì„ íƒ",
        options=candidates,
        default=["CMR", "INDUSTRIAL_AREA", "SELF_FINANCE"],  # ê¸°ë³¸: ì „ë¶€
        help="ì›í•˜ëŠ” ë³€ìˆ˜ë§Œ ê³¨ë¼ íˆíŠ¸ë§µ/íƒ€ê¹ƒ ìƒê´€ ë§‰ëŒ€ë¥¼ ë´…ë‹ˆë‹¤."
    )

    # 4-2) (ì„ íƒ) íƒ€ê¹ƒ ì»¬ëŸ¼ ì„ íƒ UI (target_colì´ ì—†ë‹¤ë©´ ëŒ€ì²´)
    if not target_col or target_col not in num_cols_all:
        tgt_opt = ["(ì„ íƒ ì•ˆ í•¨)"] + num_cols_all
        tgt_pick = st.selectbox("íƒ€ê¹ƒ ë³€ìˆ˜ ì„ íƒ (ì„ íƒ ì‹œ íƒ€ê¹ƒ ìƒê´€ ë§‰ëŒ€ í‘œì‹œ)", tgt_opt, index=0)
        target = None if tgt_pick == "(ì„ íƒ ì•ˆ í•¨)" else tgt_pick
    else:
        target = target_col  # ê¸°ì¡´ì— ì •í•œ íƒ€ê¹ƒ ì‚¬ìš©

    # 4-3) íˆíŠ¸ë§µ
    if len(sel_vars) >= 2:
        corr = filtered[sel_vars].corr()
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(
            corr,
            annot=True,       # ì…€ ì•ˆì— ìˆ«ì í‘œì‹œ
            fmt=".2f",        # ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€
            cmap="Blues",
            ax=ax
        )
        ax.set_title("Correlation Heatmap (Selected Variables)")
        st.pyplot(fig)
    else:
        st.info("ìƒê´€ íˆíŠ¸ë§µì„ ë³´ë ¤ë©´ 2ê°œ ì´ìƒ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

    # 4-4) íƒ€ê¹ƒê³¼ì˜ ìƒê´€ bar
    if target and target in filtered.columns and len(sel_vars) >= 1:
        corr_t = filtered[sel_vars + [target]].corr()[target].drop(labels=[target])
        use_abs = st.checkbox("ì ˆëŒ€ê°’ ê¸°ì¤€ ì •ë ¬", value=False)
        corr_t = corr_t.reindex(corr_t.abs().sort_values(ascending=False).index) if use_abs \
                else corr_t.sort_values(ascending=False)

        st.markdown(f"**íƒ€ê¹ƒ({target})ê³¼ì˜ í”¼ì–´ìŠ¨ ìƒê´€**")
        fig2, ax2 = plt.subplots(figsize=(6, max(2, 0.3*len(corr_t))))
        corr_t.plot(kind="barh", ax=ax2)
        ax2.invert_yaxis()
        ax2.set_xlabel("corr with target")
        st.pyplot(fig2)

    st.divider()

    # 5) ì§€ë¦¬ EDA
    st.subheader("ì§€ë„ ê¸°ë°˜ ì§€ì—­ ë¹„êµ íˆíŠ¸ë§µ")
    
    # ë°ì´í„° ë¡œë“œ (ì˜ˆì‹œ CSV)
    df = pd.read_csv("./streamlit/data/streamlit_data.csv")  # YEAR, SGG_CODE, ê°’ë“¤ í¬í•¨
    geojson_obj = load_geojson("./streamlit/data/SGG_GEOJSON.geojson")
    
    # GeoJSON ìƒ˜í”Œ ì½”ë“œ ê¸¸ì´ í™•ì¸
    gj_sample_code = str(geojson_obj["features"][0]["properties"]["BJCD"])
    gj_len = len(gj_sample_code)

    # dfì˜ BJCD â†’ ë¬¸ìì—´í™” + zero-fill
    df["BJCD"] = (
        df["BJCD"].astype(str)
    )

    # ìˆ«ìí˜• ë³€ìˆ˜ í›„ë³´
    num_cols = [c for c in df.columns if df[c].dtype in ("int64", "float64") and c not in ["YEAR"]]
    map_var = st.selectbox("ì§€ë„ì— í‘œì‹œí•  ë³€ìˆ˜", num_cols)

    # ì—°ë„ ì„ íƒ
    years = sorted(df["YEAR"].unique().tolist())
    sel_year = st.selectbox("ì—°ë„ ì„ íƒ", years, index=len(years) - 1)

    # ì§€ë„ ì¶œë ¥
    draw_choropleth(df, geojson_obj, sel_year, map_var)

    
    # 6) ê·¸ë£¹ ë¹„êµ (ì„ íƒ ì»¬ëŸ¼ ì¡´ì¬ ì‹œ)
    group_keys = [c for c in ["region_type", "urban_class"] if c in filtered.columns]
    if target_col and group_keys:
        st.subheader("ê·¸ë£¹ë³„ ë¶„í¬ ë¹„êµ (Boxplot)")
        gkey = st.selectbox("ê·¸ë£¹ ì»¬ëŸ¼ ì„ íƒ", group_keys)
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.boxplot(data=filtered, x=gkey, y=target_col, ax=ax)
        ax.set_xlabel(gkey)
        ax.set_ylabel(target_col)
        st.pyplot(fig)

# ---------------------------------
# 3-3)ëª¨ë¸/ì¤‘ìš”ë„ íƒ­ ë Œë”ëŸ¬
# ---------------------------------
def render_model_tab(df: pd.DataFrame,
                     target_col: str,
                     exclude_cols: set = {"SGG_NAME", "SGG_CODE", "YEAR", "BJCD"},
                     model_paths: list = None):

    if model_paths is None:
        model_paths = [
            "./streamlit/model/ElasticNet(GridSearch)_baseline.pkl",
            "./streamlit/model/XGBoost_ensemble.pkl",
        ]

    st.subheader("ëª¨ë¸ ê²°ê³¼ Â· ë¹„êµ Â· ë³€ìˆ˜ì¤‘ìš”ë„ Â· SHAP ìš”ì•½")

    # ------- ê³µí†µ ì¤€ë¹„ -------
    if not target_col:
        st.warning("íƒ€ê¹ƒ ì»¬ëŸ¼ì„ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()
    if target_col not in df.columns:
        st.error(f"íƒ€ê¹ƒ ì»¬ëŸ¼ `{target_col}` ì´(ê°€) ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    cand_feats = [c for c in df.select_dtypes(include=["number"]).columns
                  if c not in exclude_cols and c != target_col]
    if not cand_feats:
        st.error("í•™ìŠµ ê°€ëŠ¥í•œ ìˆ«ìí˜• í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    X_all = df[cand_feats].copy()
    y_all = df[target_col].copy()

    # ------- ëª¨ë¸ ë¡œë”© -------
    loaded, errors = load_models_from_paths(model_paths)
    if errors:
        st.warning("ë¡œë“œ ì‹¤íŒ¨:\n" + "\n".join([f"- {e}" for e in errors]))
    if not loaded:
        st.stop()

    # ------- ì¼ê´„ í‰ê°€ -------
    rows = []
    aligned_feature_sets = {}
    for disp_name, model, feat_from_model in loaded:
        X_use, feat_names, missing = align_features(X_all, feat_from_model)
        if not feat_names:
            st.error(f"{disp_name}: ê³µí†µ í”¼ì²˜ ì—†ìŒ â†’ í‰ê°€ ë¶ˆê°€")
            continue
        if missing:
            st.info(f"âš ï¸ {disp_name} ëˆ„ë½ í”¼ì²˜: {missing}")

        try:
            m = evaluate_model(model, X_use, y_all)
            rows.append({
                "Model": disp_name,
                "Rows": len(X_use),
                "Features": len(feat_names),
                "RMSE": m["rmse"], "MAE": m["mae"], "RÂ²": m["r2"]
            })
            aligned_feature_sets[disp_name] = (X_use, feat_names)
        except Exception as e:
            st.info(f"{disp_name}: ì˜ˆì¸¡/í‰ê°€ ì‹¤íŒ¨ â€” {e}")

    if not rows:
        st.stop()

    res_df = pd.DataFrame(rows).sort_values(by="RMSE").reset_index(drop=True)
    st.subheader("ğŸ“ˆ í‰ê°€ ì§€í‘œ")
    st.dataframe(res_df, use_container_width=True)

    # ------- ìƒì„¸ ë¶„ì„ ëŒ€ìƒ ì„ íƒ -------
    st.divider()
    st.subheader("ìƒì„¸ ë¶„ì„ ëª¨ë¸ ì„ íƒ")
    sel_model_name = st.selectbox("ëª¨ë¸ ì„ íƒ", [r["Model"] for r in rows])
    sel_tuple = next((t for t in loaded if t[0] == sel_model_name), None)
    if sel_tuple is None:
        st.stop()
    disp_name, sel_model, _ = sel_tuple
    X_use, feat_names = aligned_feature_sets[disp_name][:2]

    # ------- ë³€ìˆ˜ì¤‘ìš”ë„ -------
    st.subheader("ğŸ¯ ë³€ìˆ˜ì¤‘ìš”ë„")
    importance = get_importance_series(sel_model, feat_names)
    if importance is not None and len(importance) > 0:
        top_k = st.slider("ìƒìœ„ Nê°œ í‘œì‹œ", 5, min(30, len(importance)), min(15, len(importance)))
        fig_imp, ax_imp = plt.subplots(figsize=(6, 5))
        importance.head(top_k)[::-1].plot(kind="barh", ax=ax_imp)
        ax_imp.set_title(f"Top Feature Importances â€” {disp_name}")
        ax_imp.set_xlabel("Importance / |coef|")
        ax_imp.set_ylabel("Feature")
        st.pyplot(fig_imp)
    else:
        st.info("ì´ ëª¨ë¸ì—ì„œëŠ” ë³€ìˆ˜ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ------- SHAP ìš”ì•½ + í–‰ë³„ ë¡œì»¬ ì¤‘ìš”ë„ -------
    st.subheader("ğŸ§  SHAP ìš”ì•½")

    try:

        # 1) Explainer ì¤€ë¹„
        explainer, method, _ = choose_shap_explainer(sel_model, X_use)

        # 2) ìš”ì•½ìš© SHAP (ìƒ˜í”Œë§)
        sample_n = st.slider("SHAP ê³„ì‚° ìƒ˜í”Œ ìˆ˜(ìš”ì•½ìš©)", 100, min(2000, len(X_use)), min(500, len(X_use)))
        X_sample = X_use.sample(n=sample_n, random_state=42) if len(X_use) > sample_n else X_use

        sv_summary = explainer.shap_values(X_sample)
        # ë‹¤ì°¨ì› ë°©ì–´
        if isinstance(sv_summary, list):
            sv_summary = np.array(sv_summary)
        if getattr(sv_summary, "ndim", 2) == 3:
            sv_summary = sv_summary[0]

        st.write(f"**SHAP Summary â€” {disp_name} (method: {method})**")
        fig_shap = plt.figure(figsize=(7, 5))
        shap.summary_plot(sv_summary, X_sample, show=False)
        st.pyplot(fig_shap)

        st.write("**í‰ê·  |SHAP| ìƒìœ„ 15ê°œ (ìš”ì•½)**")
        st.dataframe(mean_abs_shap_top(sv_summary, X_sample, top_k=15), use_container_width=True)

        st.divider()

        # 3) í–‰ ì„ íƒ â†’ ë¡œì»¬ SHAP
        st.subheader("ğŸ” ì‹œêµ°êµ¬ë³„ ë¡œì»¬ ì¤‘ìš”ë„")

        # í–‰ ì‹ë³„ ì»¬ëŸ¼ ìë™ ì„ íƒ
        if "SGG_NAME" in df.columns:
            id_col = "SGG_NAME"
        elif "SGG_CODE" in df.columns:
            id_col = "SGG_CODE"
        else:
            id_col = None  # ì¸ë±ìŠ¤ë¡œ ê³ ë¦„

        # ì„ íƒ ëª©ë¡
        if id_col:
            candidates = df.loc[X_use.index, id_col].astype(str).tolist()
            default_idx = 0
            sel_label = st.selectbox(f"í–‰(ì‹œêµ°êµ¬) ì„ íƒ â€” ê¸°ì¤€: {id_col}", candidates, index=default_idx)
            # ì„ íƒ ë¼ë²¨ â†’ ì›ë³¸ ì¸ë±ìŠ¤ ì°¾ê¸° (ë™ëª…ì´ ë§ìœ¼ë©´ ì²« ë²ˆì§¸)
            match_idx = df.loc[X_use.index][df.loc[X_use.index, id_col].astype(str) == str(sel_label)].index
            if len(match_idx) == 0:
                st.info("ì„ íƒí•œ ì‹œêµ°êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
            row_idx = match_idx[0]
        else:
            # ì¸ë±ìŠ¤ë¡œ ì„ íƒ
            idx_list = list(map(str, X_use.index.tolist()))
            sel_idx_str = st.selectbox("í–‰(ì¸ë±ìŠ¤) ì„ íƒ", idx_list, index=0)
            row_idx = int(sel_idx_str) if sel_idx_str.isdigit() else X_use.index[0]

        # ì„ íƒ í–‰ì˜ X(1Ã—features)
        X_row = X_use.loc[[row_idx]]

        # 4) ë¡œì»¬ SHAP ê³„ì‚° (1í–‰)
        sv_row = explainer.shap_values(X_row)
        if isinstance(sv_row, list):
            sv_row = np.array(sv_row)
        if getattr(sv_row, "ndim", 3) == 3:
            sv_row = sv_row[0]               # (1, n_features)
        sv_row = np.ravel(sv_row)            # (n_features,)

        # 5) ë¡œì»¬ ì¤‘ìš”ë„ í…Œì´ë¸” & ë°”ì°¨íŠ¸ (Top-k)
        k_local = st.slider("ë¡œì»¬ ì¤‘ìš”ë„ â€” ìƒìœ„ Nê°œ", 5, min(30, len(feat_names)), min(10, len(feat_names)))
        local_series = pd.Series(np.abs(sv_row), index=feat_names).sort_values(ascending=False)

        st.write("**ì„ íƒ í–‰ ë¡œì»¬ |SHAP| ìƒìœ„**")
        st.dataframe(local_series.head(k_local).rename("local|SHAP|").to_frame(), use_container_width=True)

        fig_local, ax_local = plt.subplots(figsize=(6, 5))
        local_series.head(k_local)[::-1].plot(kind="barh", ax=ax_local)
        ax_local.set_title("Local Feature Importance (|SHAP|)")
        ax_local.set_xlabel("|SHAP|")
        ax_local.set_ylabel("Feature")
        st.pyplot(fig_local)

        # (ì„ íƒ) ë°©í–¥ì„±ê¹Œì§€ ë³´ê³  ì‹¶ìœ¼ë©´ ì›ì‹œ SHAP ê°’ìœ¼ë¡œë„ í‘œì‹œ
        with st.expander("ë¶€í˜¸ í¬í•¨ SHAP ê°’ ë³´ê¸° (ì„ íƒ)", expanded=False):
            signed_series = pd.Series(sv_row, index=feat_names).sort_values(key=lambda x: np.abs(x), ascending=False)
            st.dataframe(signed_series.head(k_local).rename("SHAP (signed)").to_frame(), use_container_width=True)

    except Exception as e:
        st.info(f"SHAP ê³„ì‚° ë¶ˆê°€/ë¡œì»¬ ì¤‘ìš”ë„ ì—ëŸ¬: {e}")

# ---------------------------------
# 3-4)ëª¨ë¸/ì¤‘ìš”ë„ íƒ­ ë Œë”ëŸ¬
# ---------------------------------
def render_region_tab(
    df: pd.DataFrame,
    target_col: str,
    geojson_path: str = "./streamlit/data/SGG_GEOJSON.geojson",
    df_code_col: str = "BJCD",
    df_name_col: str = "SGG_NAME",
    key_ns: str = "region", 
):
    # í‚¤ í—¬í¼
    k = lambda name: f"{key_ns}:{name}"

    st.subheader("ì§€ì—­ë³„ ìƒì„¸ Â· ì§€ë„ Â· ë¹„êµ")

    # --- ì ê²€/ì „ì²˜ë¦¬ ---
    for c in [target_col, df_code_col, df_name_col]:
        if c not in df.columns:
            st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: `{c}`")
            st.stop()
    df = ensure_bjcd_string(df, col=df_code_col)

    # --- ì»¨íŠ¸ë¡¤ ---
    num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != target_col]
    main_var = st.selectbox("ì§€ë„ì— í‘œì‹œí•  ë³€ìˆ˜", [target_col] + num_cols, index=0, key=k("main_var"))

    years = sorted(df["YEAR"].dropna().unique().tolist()) if "YEAR" in df.columns else None
    year = st.selectbox("ì—°ë„ ì„ íƒ", years, index=len(years)-1, key=k("year")) if years else None
    dff = df if year is None else df[df["YEAR"] == year].copy()
    
    # --- íŒì—…ì— ë„£ì„ ì»¬ëŸ¼ ê²°ì • ---
    # target_colì„ ìš°ì„ ('youth_move_rate' ê³„ì—´), ë‚˜ë¨¸ì§€ëŠ” ì¼€ì´ìŠ¤ ë¬´ì‹œë¡œ íƒìƒ‰

    youth_col = target_col or find_col_ci(dff, "youth_net_move_rate")
    cmr_col   = find_col_ci(dff, "cmr")
    ind_col   = find_col_ci(dff, "industrial_area", "industrial_Area")
    self_col  = find_col_ci(dff, "self_finance", "selfFinance")

    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ ì‚¬ìš©
    popup_cols = [c for c in [youth_col, cmr_col, ind_col, self_col] if c]

    if dff.empty:
        st.warning("ì„ íƒí•œ ì¡°ê±´ì˜ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        st.stop()

    # ì§€ì—­ ìƒì„¸ ì¹´ë“œ (ì—¬ê¸°ì„œë¶€í„° key ì œê±°)
    default_bjcd = st.session_state.get("selected_bjcd")
    if default_bjcd and default_bjcd in dff[df_code_col].values:
        default_region = dff.loc[dff[df_code_col] == default_bjcd, df_name_col].iloc[0]
    else:
        default_region = None

    region_opts = sorted(dff[df_name_col].dropna().astype(str).unique().tolist())
    idx_default = region_opts.index(default_region) if default_region in region_opts else 0
    sel_region = st.selectbox("ì§€ì—­ ì„ íƒ", region_opts, index=idx_default, key=k("region_select"))

    row = dff[dff[df_name_col].astype(str) == str(sel_region)].iloc[0]
    sel_bjcd = str(row[df_code_col])
    val = float(row[main_var]) if pd.notnull(row[main_var]) else np.nan
    pct = pct_rank(dff[main_var], val)

    c1, c2, c3 = st.columns(3)
    c1.metric("ì§€ì—­ëª…", sel_region)  # âŒ key ì œê±°
    c2.metric(f"{main_var}", f"{val:,.3f}" if pd.notnull(val) else "NA")
    c3.metric("ë¶„ìœ„(%)", f"{pct:.1f}%" if pd.notnull(pct) else "NA")

    # ë°•ìŠ¤í”Œë¡¯ ë Œë”ë§ ì£¼ì„ì²˜ë¦¬
    # fig_box, ax_box = plt.subplots(figsize=(4, 2.4))
    # ax_box.boxplot(dff[main_var].dropna(), vert=False, widths=0.5)
    # if pd.notnull(val): ax_box.axvline(val, linestyle="--", linewidth=2)
    # ax_box.set_title(f"{main_var} ë¶„í¬ì™€ ì„ íƒ ì§€ì—­")
    # st.pyplot(fig_box)  # âŒ key ì—†ìŒ

    st.divider()
    
    # ì§€ë„
    try:
        with open(geojson_path, "r", encoding="utf-8") as f:
            gjson = json.load(f)
    except Exception as e:
        st.error(f"GeoJSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()

    val_map = make_val_map(dff, df_code_col, popup_cols, df_name_col)
    label_map = {}
    if youth_col: label_map[youth_col] = "ì²­ë…„ ìˆœ ì´ë™ë¥ "
    if cmr_col:   label_map[cmr_col]   = "ì¡°í˜¼ì¸ìœ¨"
    if ind_col:   label_map[ind_col]   = "ê³µì—…ì§€ì—­ ë©´ì "
    if self_col:  label_map[self_col]  = "ì¬ì •ìë¦½ë„"

    # --- (5) ì§€ë„ ìƒì„± + ì±„ìƒ‰ ---
    m = folium.Map(location=[36.5, 127.9], zoom_start=7, tiles="cartodbpositron")
    folium.Choropleth(
        geo_data=gjson,
        data=dff,
        columns=[df_code_col, main_var],
        key_on="feature.properties.BJCD",
        fill_color="YlOrRd",
        nan_fill_color="lightgray",
        fill_opacity=0.75,
        line_opacity=0.5,
        legend_name=f"{main_var}",
    ).add_to(m)

    # ì§€ì—­ ì„ íƒê°’ì„ ì„¸ì…˜ì—ë„ ê³µìœ  (ëª¨ë¸/ì •ì±… íƒ­ê³¼ ì—°ë™ ì›í•˜ë©´)
    # st.session_state["selected_bjcd"] = sel_bjcd

    # ì„ íƒ ì§€ì—­ ìë™ í•˜ì´ë¼ì´íŠ¸ + íŒì—… ì˜¤í”ˆ + ì˜ì—­ìœ¼ë¡œ ì¤Œ
    if sel_bjcd:
        feat_sel = next(
            (f for f in gjson.get("features", []) if str(f.get("properties", {}).get("BJCD", "")) == str(sel_bjcd)),
            None
        )
        if feat_sel:
            folium.GeoJson(
                feat_sel,
                style_function=lambda x: {"fillOpacity": 0, "color": "#2a66ff", "weight": 3},
                highlight_function=lambda x: {"weight": 3, "color": "#2a66ff"},
                popup=folium.Popup(
                    popup_html_for_code(sel_bjcd, val_map, popup_cols, label_map, df_name_col),
                    max_width=300,
                    show=True  # â† ì˜¤í”ˆ ìƒíƒœë¡œ
                ),
                name="selected-region"
            ).add_to(m)

            b = feature_bounds(feat_sel)
            if b:
                m.fit_bounds(b)
        else:
            st.caption("ì„ íƒí•œ ì§€ì—­(BJCD)ì´ GeoJSONì— ì—†ìŠµë‹ˆë‹¤.")

    for feat in gjson.get("features", []):
        code_ = str(feat["properties"].get("BJCD", ""))
        rec = val_map.get(code_)
        if rec:
            lines = [f"<b>{rec.get(df_name_col, '')}</b>", f"CODE: {code_}"]
            for col in popup_cols:
                v = rec.get(col)
                label = label_map.get(col, col)
                if isinstance(v, (int, float, np.number)) and pd.notnull(v):
                    lines.append(f"{label}: {v:,.3f}")
                elif v is not None and str(v) != "nan":
                    lines.append(f"{label}: {v}")
            popup_html = "<br>".join(lines)
        else:
            popup_html = f"CODE: {code_}<br>(ë°ì´í„° ì—†ìŒ)"

        folium.GeoJson(
            feat,
            style_function=lambda x: {"fillOpacity": 0, "weight": 0},
            popup=folium.Popup(popup_html, max_width=280)
        ).add_to(m)

    # --- (7) ì§€ë„ ë Œë” ---
    out = st_folium(m, height=540, use_container_width=True)

    st.divider()

    # ë¹„êµ (4ê°œ ì§€í‘œ ê³ ì •: CMR, SELF_FINANCE, INDUSTRIAL_AREA, YOUTH_NET_MOVE_RATE)
    compare_targets = st.multiselect("ë¹„êµí•  ì§€ì—­ ì„ íƒ", region_opts, default=[sel_region], key=k("compare"))

    # 1) ì»¬ëŸ¼ ìë™ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì/ì¼€ì´ìŠ¤ ë¬´ì‹œ)
    col_map = {
        "CMR":                 find_col_ci(dff, "CMR", "cmr"),
        "SELF_FINANCE":        find_col_ci(dff, "SELF_FINANCE", "self_finance", "selfFinance"),
        "INDUSTRIAL_AREA":     find_col_ci(dff, "INDUSTRIAL_AREA", "industrial_area", "industrial_Area"),
        "YOUTH_NET_MOVE_RATE": find_col_ci(dff, "YOUTH_NET_MOVE_RATE", "youth_net_move_rate", "youth_move_rate", target_col),
    }
    use_map = {k: v for k, v in col_map.items() if v}  # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ

    if len(use_map) < 1:
        st.warning("ë¹„êµí•  ì§€í‘œ ì»¬ëŸ¼ì„ ë°ì´í„°ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        # 2) ë¹„êµ í…Œì´ë¸” êµ¬ì„±
        cols_for_table = [df_name_col, df_code_col] + list(use_map.values())
        comp = dff[dff[df_name_col].astype(str).isin(compare_targets)][cols_for_table].copy()
        comp = comp.rename(columns={df_name_col: "REGION", df_code_col: "BJCD", **use_map})

        # ìˆ«ìí˜• ë³´ì •
        for m in use_map.keys():
            comp[m] = pd.to_numeric(comp[m], errors="coerce")

        st.dataframe(comp.reset_index(drop=True), use_container_width=True)

        # 3) ê·¸ë£¹í˜• ë§‰ëŒ€ê·¸ë˜í”„ (ì§€í‘œ Ã— ì§€ì—­)
        if len(comp) >= 1:
            metrics = list(use_map.keys())  # ['CMR','SELF_FINANCE','INDUSTRIAL_AREA','YOUTH_NET_MOVE_RATE']
            x = np.arange(len(metrics))
            width = 0.8 / max(1, len(comp))  # ì§€ì—­ ìˆ˜ì— ë”°ë¼ ë§‰ëŒ€ í­ ì¡°ì •

            fig, ax = plt.subplots(figsize=(8, 4))
            for i, (_, r) in enumerate(comp.iterrows()):
                y = [r.get(m) for m in metrics]
                ax.bar(x + i*width - (len(comp)-1)*width/2, y, width, label=str(r["REGION"]))

            ax.set_xticks(x)
            ax.set_xticklabels(metrics, rotation=20, ha="right")
            ax.set_title("ì§€ì—­ ë¹„êµ")
            ax.set_xlabel("ì§€í‘œ")
            ax.set_ylabel("ê°’")
            ax.legend()
            st.pyplot(fig)

# ---------------------------------
# 3-5)ì •ì±… ì‹œë‚˜ë¦¬ì˜¤ íƒ­ ë Œë”ëŸ¬
# ---------------------------------
def render_policy_tab(
    df: pd.DataFrame,
    target_col: str,
    model_paths: list = None,
    df_code_col: str = "BJCD",
    df_name_col: str = "SGG_NAME",
    key_ns: str = "policy",
):
    """
    ì •ì±… ì‹œë‚˜ë¦¬ì˜¤(What-if) Â· í•µì‹¬ ë³€ìˆ˜ ìŠ¬ë¼ì´ë” Â· ê²°ê³¼ ë¹„êµ
    """
    k = lambda name: f"{key_ns}:{name}"
    st.subheader("ì •ì±… ì‹œë‚˜ë¦¬ì˜¤ (What-if) â€” ë³€ìˆ˜ ì¡°ì •ê³¼ ê²°ê³¼ ë¹„êµ")

    # ê¸°ë³¸ê°’: ë‘ ëª¨ë¸ ë¡œì»¬ ê²½ë¡œ
    if model_paths is None:
        model_paths = [
            "/mnt/data/ElasticNet(GridSearch)_baseline.pkl",
            "/mnt/data/XGBoost_ensemble.pkl",
        ]

    # ------- ë°ì´í„° ì ê²€/ì¤€ë¹„ -------
    for c in [target_col, df_code_col, df_name_col]:
        if c not in df.columns:
            st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: `{c}`")
            st.stop()
    df = ensure_bjcd_string(df, col=df_code_col)

    years = sorted(df["YEAR"].dropna().unique().tolist()) if "YEAR" in df.columns else None
    year = st.selectbox("ê¸°ì¤€ ì—°ë„ ì„ íƒ", years, index=len(years)-1 if years else 0, key=k("year")) if years else None
    dff = df if year is None else df[df["YEAR"] == year].copy()
    if dff.empty:
        st.warning("ì„ íƒ ì—°ë„ì˜ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        st.stop()

    # ìˆ«ìí˜• í”¼ì²˜(íƒ€ê¹ƒ ì œì™¸)
    EXCLUDE_COLS = {df_code_col, "YEAR"}
    num_feats = [
    c for c in dff.select_dtypes(include=[np.number]).columns
    if c not in EXCLUDE_COLS and c != target_col]

    # ------- ëª¨ë¸ ë¡œë”© & ì„ íƒ -------
    loaded, errors = load_models_from_paths(model_paths)
    if errors:
        st.warning("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:\n" + "\n".join([f"- {e}" for e in errors]))
    if not loaded:
        st.stop()

    model_name_list = [name for name, _, _ in loaded]
    sel_model_name = st.selectbox("ì‹œë‚˜ë¦¬ì˜¤ì— ì‚¬ìš©í•  ëª¨ë¸", model_name_list, key=k("model"))
    # ì„ íƒ ëª¨ë¸ íŠœí”Œ
    disp_name, model, feat_from_model = next((t for t in loaded if t[0] == sel_model_name), loaded[0])

    # í”¼ì²˜ ì •í•©ì„±
    X_all = dff[num_feats].copy()
    X_use, feat_names, missing = align_features(X_all, feat_from_model)
    if not feat_names:
        st.error("ëª¨ë¸ê³¼ ì¼ì¹˜í•˜ëŠ” í”¼ì²˜ê°€ ì—†ì–´ ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    if missing:
        st.info(f"âš ï¸ ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” ëˆ„ë½ í”¼ì²˜: {missing}")

    # ------- ì§€ì—­ ë²”ìœ„ ì„ íƒ -------
    st.markdown("### ì§€ì—­ ë²”ìœ„")
    default_bjcd = st.session_state.get("selected_bjcd")
    mode = st.radio("ì ìš© ëŒ€ìƒ", ["ì „ì²´", "ì§€ì—­ ì„ íƒ"], horizontal=True, key=k("scope"))

    if mode == "ì „ì²´":
        idx_scope = X_use.index
    elif mode == "ì§€ì—­ ì„ íƒ":
        region_opts = dff[df_name_col].dropna().astype(str).unique().tolist()
        regions = st.multiselect("ì§€ì—­ ì„ íƒ", sorted(region_opts), key=k("regions"))
        if not regions:
            st.stop()
        idx_scope = dff[dff[df_name_col].astype(str).isin(regions)].index.intersection(X_use.index)
        if len(idx_scope) == 0:
            st.warning("ì„ íƒ ì§€ì—­ì´ ëª¨ë¸ ì…ë ¥ ì¸ë±ìŠ¤ì™€ êµì§‘í•©ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
    else:
        if not default_bjcd:
            st.info("ì§€ë„ íƒ­ì—ì„œ ì§€ì—­ì„ í´ë¦­í•˜ë©´ BJCDê°€ ì €ì¥ë©ë‹ˆë‹¤. (st.session_state['selected_bjcd'])")
            st.stop()
        idx_scope = dff[dff[df_code_col].astype(str) == str(default_bjcd)].index.intersection(X_use.index)
        if len(idx_scope) == 0:
            st.warning("ì„ íƒëœ BJCDê°€ í˜„ì¬ ë°ì´í„° ì¸ë±ìŠ¤ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            st.stop()

    X_base = X_use.loc[idx_scope].copy()
    names_scope = dff.loc[idx_scope, df_name_col].astype(str)

    # ------- ë³€ìˆ˜ ì¡°ì • ìŠ¬ë¼ì´ë” -------
    st.markdown("### í•µì‹¬ ë³€ìˆ˜ ì¡°ì •")

    # ìë™ ì»¬ëŸ¼ ë§¤ì¹­(ëŒ€/ì†Œë¬¸ì ë¬´ì‹œ)
    col_CMR   = find_col_ci(dff, "CMR", "cmr")
    col_SELF  = find_col_ci(dff, "SELF_FINANCE", "self_finance", "selfFinance")
    col_IND   = find_col_ci(dff, "INDUSTRIAL_AREA", "industrial_area", "industrial_Area")

    # ìŠ¬ë¼ì´ë”(Â±50%) â€” ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë…¸ì¶œ
    pct_changes = {}
    col_labels  = []
    for label, col in [("CMR", col_CMR), ("SELF_FINANCE", col_SELF), ("INDUSTRIAL_AREA", col_IND)]:
        if col and col in feat_names:
            pct = st.slider(f"{label} ì¦ê°(%)", -50, 50, 0, step=5, key=k(f"pct_{label}"))
            pct_changes[col] = pct / 100.0
            col_labels.append((label, col))
        elif col and col not in feat_names:
            st.caption(f"â€¢ {label} ì»¬ëŸ¼ì€ ë°ì´í„°ì—” ìˆìœ¼ë‚˜ ì„ íƒ ëª¨ë¸ í”¼ì²˜ì— í¬í•¨ë˜ì§€ ì•Šì•„ ì¡°ì •ì´ ì ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # ì¶”ê°€ ë³€ìˆ˜(ì˜µì…˜)
    with st.expander("ì¶”ê°€ ë³€ìˆ˜ ì¡°ì • (ì„ íƒ)", expanded=False):
        other_feats = [c for c in feat_names if c not in [c for _, c in col_labels]]
        add_cols = st.multiselect("ì¶”ê°€ë¡œ ì¡°ì •í•  ë³€ìˆ˜ ì„ íƒ", other_feats, key=k("extra_feats"))
        for col in add_cols:
            pct = st.slider(f"{col} ì¦ê°(%)", -50, 50, 0, step=5, key=k(f"pct_{col}"))
            pct_changes[col] = pct / 100.0

    # ê²€ì¦
    if len(pct_changes) == 0:
        st.info("ì¡°ì •í•  ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        st.stop()

    # ------- ì‹œë‚˜ë¦¬ì˜¤ ì ìš© & ì˜ˆì¸¡ -------
    X_scn = X_base.copy()
    # ì›ë³¸ ë¶„í¬ ê³¼ë„ ì´íƒˆ ë°©ì§€ìš© í´ë¦¬í•‘ ë²”ìœ„
    q_low  = X_use.quantile(0.01)
    q_high = X_use.quantile(0.99)

    for col, pct in pct_changes.items():
        if col in X_scn.columns:
            X_scn[col] = X_scn[col] * (1.0 + pct)
            # ë¶„í¬ ë°– ê·¹ë‹¨ì¹˜ í´ë¦¬í•‘
            X_scn[col] = X_scn[col].clip(lower=q_low.get(col, None), upper=q_high.get(col, None))

    # ì˜ˆì¸¡
    try:
        y_base = model.predict(X_base)
        y_scn  = model.predict(X_scn)
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
        st.stop()

    st.divider()
    # ------- ê²°ê³¼ ë¹„êµ -------
    res = pd.DataFrame({
        "REGION": names_scope.values,
        "BASELINE": y_base,
        "SCENARIO": y_scn,
    }, index=idx_scope)
    res["DELTA"] = res["SCENARIO"] - res["BASELINE"]
    res["DELTA_%"] = np.where(res["BASELINE"] != 0, res["DELTA"] / np.abs(res["BASELINE"]) * 100.0, np.nan)

    st.markdown("### ê²°ê³¼ ë¹„êµ")
    st.dataframe(
        res.reset_index(drop=True).sort_values(by="DELTA", ascending=False),
        use_container_width=True
    )

    # ìš”ì•½ ì¹´ë“œ
    c1, c2, c3 = st.columns(3)
    c1.metric("í‰ê·  ë³€í™”", f"{res['DELTA'].mean():,.3f}")
    c2.metric("ìƒìŠ¹ ì§€ì—­ ìˆ˜", int((res["DELTA"] > 0).sum()))
    c3.metric("í•˜ë½ ì§€ì—­ ìˆ˜", int((res["DELTA"] < 0).sum()))

    # ê·¸ë˜í”„
    st.divider()
    # --- ë³€í™”ëŸ‰ ë§‰ëŒ€ê·¸ë˜í”„ (ìƒìœ„/í•˜ìœ„) ---
    st.markdown("#### ë³€í™”ëŸ‰ ë§‰ëŒ€ê·¸ë˜í”„ (ìƒìœ„/í•˜ìœ„)")

    n = len(res)
    if n <= 0:
        st.info("í‘œì‹œí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    elif n == 1:
        # ìŠ¬ë¼ì´ë” ì—†ì´ ë‹¨ì¼ ë§‰ëŒ€ë§Œ í‘œì‹œ
        st.caption("ì§€ì—­ì´ 1ê°œë¿ì´ë¼ ìŠ¬ë¼ì´ë” ì—†ì´ í‘œì‹œí•©ë‹ˆë‹¤.")
        res_sorted = res.sort_values(by="DELTA", ascending=False)
        show = res_sorted
        fig, ax = plt.subplots(figsize=(8, 4))
        ax.bar(show["REGION"].astype(str), show["DELTA"])
        ax.set_title(f"ì˜ˆì¸¡ ë³€í™”ëŸ‰ (ëª¨ë¸: {disp_name})")
        ax.set_xlabel("ì§€ì—­")
        ax.set_ylabel("Î” (Scenario - Baseline)")
        plt.xticks(rotation=30, ha="right")
        st.pyplot(fig)
    else:
        # n >= 2ì¸ ê²½ìš°ì—ë§Œ ìŠ¬ë¼ì´ë” ì‚¬ìš© (min < max ë³´ì¥)
        maxN = min(30, n)              # ë°ì´í„° ìˆ˜ ì´ë‚´ë¡œ ìƒí•œ
        defaultN = min(10, maxN)       # ê¸°ë³¸ê°’ì€ ìµœëŒ€ 10
        topN = st.slider("í‘œì‹œí•  ìƒ/í•˜ìœ„ N",
                        min_value=1,
                        max_value=maxN,
                        value=defaultN,
                        step=1,
                        key=k("topN"))

        res_sorted = res.sort_values(by="DELTA", ascending=False)
        # ìƒìœ„ N + í•˜ìœ„ N ê²°í•© (ì¤‘ë³µ ì œê±°)
        show = pd.concat([res_sorted.head(topN), res_sorted.tail(topN)]).drop_duplicates()

        fig, ax = plt.subplots(figsize=(8, 4))
        ax.bar(show["REGION"].astype(str), show["DELTA"])
        ax.set_title(f"ì˜ˆì¸¡ ë³€í™”ëŸ‰ (ëª¨ë¸: {disp_name})")
        ax.set_xlabel("ì§€ì—­")
        ax.set_ylabel("Î” (Scenario - Baseline)")
        plt.xticks(rotation=30, ha="right")
        st.pyplot(fig)

    # ì ìš© ë³€ìˆ˜ ìš”ì•½
    with st.expander("ì ìš©ëœ ë³€ìˆ˜ ì¡°ì • ìš”ì•½"):
        adj_tbl = pd.DataFrame(
            [(lab if lab else col, col, f"{pct*100:+.0f}%") for lab, col in col_labels] +
            [(None, c, f"{pct*100:+.0f}%") for c, pct in pct_changes.items() if c not in [c for _, c in col_labels]],
            columns=["Label", "Column", "Change"]
        )
        st.dataframe(adj_tbl, use_container_width=True)

# ---------------------------------
# 3-6)ë¬¸ì„œ/ë§í¬ íƒ­ ë Œë”ëŸ¬
# ---------------------------------
def render_docs_tab(
    df: pd.DataFrame,
    target_col: str,
    code_col: str = "BJCD",
    name_col: str = "SGG_NAME",
    key_ns: str = "docs",
):
    k = lambda name: f"{key_ns}:{name}"

    st.subheader("ğŸ”— ë¬¸ì„œ/ë§í¬ ëª¨ìŒ")

    # ì„¸ì…˜ ìƒíƒœì— ë§í¬ ëª©ë¡ ì¤€ë¹„ (ììœ ë¡­ê²Œ ë¼ë²¨/URL ì¶”ê°€ ê°€ëŠ¥)
    if "docs_links" not in st.session_state:
        st.session_state["docs_links"] = [
            {"label": "Git", "url": "https://github.com/outflow-project/population-outflow"},
            {"label": "ë³´ê³ ì„œ", "url": "https://drive.google.com/file/d/12XRVuKOucmzVNWLxbsJVoCGfMXDYNS31/view?usp=sharing"},
            {"label": "WBS", "url": "https://docs.google.com/spreadsheets/d/e/2PACX-1vRb9ohd88EGHGt8LsJhzMdrWoJuaOZsXOY50SoAreutAd5NDPouQTa1Y0wSdAIevUNgAa5AMlqC9Rm8/pubhtml?gid=1115838130&single=true"},
            {"label": "ë°œí‘œìë£Œ", "url": ""},
        ]

    mode = st.radio("ëª¨ë“œ ì„ íƒ", ["ë³´ê¸°"], horizontal=True, key=k("mode"))

    if mode == "í¸ì§‘":
        # ììœ ë¡­ê²Œ í–‰ ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥í•œ ì—ë””í„°
        import pandas as pd
        links_df = pd.DataFrame(st.session_state["docs_links"])
        edited = st.data_editor(
            links_df,
            num_rows="dynamic",           # í–‰ ì¶”ê°€/ì‚­ì œ í—ˆìš©
            use_container_width=True,
            key=k("editor"),
        )
        col_save, col_reset = st.columns([1,1])
        with col_save:
            if st.button("ì €ì¥", key=k("save")):
                st.session_state["docs_links"] = edited.to_dict("records")
                st.success("ë§í¬ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        with col_reset:
            if st.button("ê¸°ë³¸ê°’ ë³µì›", key=k("reset")):
                st.session_state["docs_links"] = [
                    {"label": "Git", "url": ""},
                    {"label": "ë³´ê³ ì„œ", "url": ""},
                    {"label": "WBS", "url": ""},
                    {"label": "ë°œí‘œìë£Œ", "url": ""},
                ]
                st.info("ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì›í–ˆìŠµë‹ˆë‹¤.")
    else:
        # ë³´ê¸° ëª¨ë“œ
        links = st.session_state["docs_links"]
        if not links:
            st.info("ë“±ë¡ëœ ë§í¬ê°€ ì—†ìŠµë‹ˆë‹¤. â€˜í¸ì§‘â€™ ëª¨ë“œì—ì„œ ì¶”ê°€í•˜ì„¸ìš”.")
        for item in links:
            label = item.get("label") or "ë§í¬"
            url = (item.get("url") or "").strip()
            if url:
                st.markdown(f"- **{label}**: [{url}]({url})")
            else:
                st.markdown(f"- **{label}**: _(ë¯¸ì„¤ì •)_")


# ---------------------------------
# 4) ì‚¬ì´ë“œë°”
# ---------------------------------
st.sidebar.title("ğŸ“Š 2ì¡° - ë‚¨ì•„ì£¼ì„¸ìœ ")
file = st.sidebar.file_uploader("ì‹œêµ°êµ¬ ì—°ë„ë³„ ë°ì´í„° CSV", type=["csv"])    
df = load_data(file)

# ì—°ë„ í•„í„°
years = sorted(df["YEAR"].dropna().unique().tolist()) if "YEAR" in df.columns else []
sel_years = st.sidebar.multiselect("ì—°ë„ í•„í„°", years, default=years)
if sel_years:
    df = df[df["YEAR"].isin(sel_years)]

# ì‹œë„ í•„í„°
if "SGG_NAME" in df.columns:
    # 1) ì‹œë„ëª… ì¶”ì¶œ
    df["SIDO_NAME"] = df["SGG_NAME"].apply(lambda x: str(x).split()[0] if pd.notna(x) else "ë¯¸ì •")
    # 2) ì‚¬ì´ë“œë°” í•„í„°
    sidos = sorted(df["SIDO_NAME"].dropna().unique().tolist())
    sel_sidos = st.sidebar.multiselect("ì‹œë„ í•„í„°", sidos, default=sidos)
    # 3) í•„í„° ì ìš©
    if sel_sidos:
        df = df[df["SIDO_NAME"].isin(sel_sidos)]

# ---------------------------------
# 5) ì•± íƒ­ êµ¬ì„±
# ---------------------------------
tab_overview, tab_eda, tab_model, tab_region, tab_policy, tab_docs = st.tabs([
    "ê°œìš”", "EDA", "ëª¨ë¸/ì¤‘ìš”ë„", "ì§€ì—­ë³„ ë¦¬í¬íŠ¸", "ì •ì±… ì‹œë‚˜ë¦¬ì˜¤", "ë¬¸ì„œ/ë§í¬"
])

with tab_overview: # ê°œìš” íƒ­
    render_overview_tab(df, PROJECT_META)

with tab_eda: # ë°ì´í„° EDA íƒ­
    render_eda_tab(df)

with tab_model:
    render_model_tab(df, target_col='YOUTH_NET_MOVE_RATE')
with tab_region:
    render_region_tab(
        df,
        target_col="YOUTH_NET_MOVE_RATE",
        geojson_path="./streamlit/data/SGG_GEOJSON.geojson",
        key_ns="region"   # íƒ­/í˜ì´ì§€ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ì£¼ë©´ ì¶©ëŒ ë°©ì§€
    )

with tab_policy:
    render_policy_tab(
        df,
        target_col="YOUTH_NET_MOVE_RATE",   # í˜„ì¬ íƒ€ê¹ƒ
        model_paths=[
            "./streamlit/model/ElasticNet(GridSearch)_baseline.pkl",
            "./streamlit/model/XGBoost_ensemble.pkl",
        ],
        df_code_col="BJCD",
        df_name_col="SGG_NAME",
        key_ns="policy"
    )

with tab_docs:
    render_docs_tab(
        df,
        target_col="YOUTH_NET_MOVE_RATE",
        code_col="BJCD",
        name_col="SGG_NAME",
        key_ns="docs"
    )